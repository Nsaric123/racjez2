{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d10638b-54cf-4bb5-bb5b-736aa60a3892",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kolokvij 2: priprema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6f9ada-f287-4790-b42a-743183c0b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk2tikz import show_parse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44fa033-1022-4aab-9efb-4fbeee1c18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d4771ac-00e2-4549-88da-2cc3a7dac85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d58b0d8-3691-432c-8580-e7b6a903d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b11786-0637-4591-bb99-65176bb6a40d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadatak 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e26d43-6e93-4d69-9632-a56e220492b4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Napišite gramatiku obogaćenu značajkama koja opisuje sljedeće rečenice:\n",
    "```\n",
    "Ovaj dječak trči.\n",
    "Ovi dječaci trče.\n",
    "Ova djevojka pleše.\n",
    "Ove djevojke plešu.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0703235-7169-4988-94dc-f7b19f002f5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grammar.fcfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile grammar.fcfg\n",
    "# grammar productions\n",
    "S -> NP[NUM=?n, GEN=?m] VP[NUM=?n, GEN=?m]\n",
    "NP[NUM=?n] -> Det[NUM=?n, GEN=?m] N[NUM=?n, GEN=?m]\n",
    "VP[NUM=?n,GEN=?m] -> V[NUM=?n,GEN=?m]\n",
    "# lexical productions\n",
    "Det[NUM=sg, GEN=m] -> 'ovaj'\n",
    "Det[NUM=sg, GEN=f] -> 'ova'\n",
    "Det[NUM=sg, GEN=n] -> 'ovo'\n",
    "Det[NUM=pl, GEN=m] -> 'ovi'\n",
    "Det[NUM=pl, GEN=f] -> 'ove'\n",
    "Det[NUM=pl, GEN=n] -> 'ova'\n",
    "N[NUM=sg,GEN=m] -> 'dječak' \n",
    "N[NUM=pl,GEN=m] -> 'dječaci'\n",
    "N[NUM=sg,GEN=f] -> 'djevojka' \n",
    "N[NUM=pl,GEN=f] -> 'djevojke'\n",
    "V[NUM=sg] -> 'trči' | 'pleše'\n",
    "V[NUM=pl] -> 'trče' | 'plešu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b8c1781-be18-4b7e-b1b7-c326197001d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# grammar productions\n",
      "S -> NP[NUM=?n, GEN=?m] VP[NUM=?n, GEN=?m]\n",
      "NP[NUM=?n] -> Det[NUM=?n, GEN=?m] N[NUM=?n, GEN=?m]\n",
      "VP[NUM=?n,GEN=?m] -> V[NUM=?n,GEN=?m]\n",
      "# lexical productions\n",
      "Det[NUM=sg, GEN=m] -> 'ovaj'\n",
      "Det[NUM=sg, GEN=f] -> 'ova'\n",
      "Det[NUM=sg, GEN=n] -> 'ovo'\n",
      "Det[NUM=pl, GEN=m] -> 'ovi'\n",
      "Det[NUM=pl, GEN=f] -> 'ove'\n",
      "Det[NUM=pl, GEN=n] -> 'ova'\n",
      "N[NUM=sg,GEN=m] -> 'dječak' \n",
      "N[NUM=pl,GEN=m] -> 'dječaci'\n",
      "N[NUM=sg,GEN=f] -> 'djevojka' \n",
      "N[NUM=pl,GEN=f] -> 'djevojke'\n",
      "V[NUM=sg] -> 'trči' | 'pleše'\n",
      "V[NUM=pl] -> 'trče' | 'plešu'\n"
     ]
    }
   ],
   "source": [
    "# CFG obogaćena s dodatnim značajkama\n",
    "nltk.data.show_cfg('grammar.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed463834-fe71-41ae-860f-0a00ff8ebc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 17 productions (start state = S[])\n",
      "    S[] -> NP[GEN=?m, NUM=?n] VP[GEN=?m, NUM=?n]\n",
      "    NP[NUM=?n] -> Det[GEN=?m, NUM=?n] N[GEN=?m, NUM=?n]\n",
      "    VP[GEN=?m, NUM=?n] -> V[GEN=?m, NUM=?n]\n",
      "    Det[GEN='m', NUM='sg'] -> 'ovaj'\n",
      "    Det[GEN='f', NUM='sg'] -> 'ova'\n",
      "    Det[GEN='n', NUM='sg'] -> 'ovo'\n",
      "    Det[GEN='m', NUM='pl'] -> 'ovi'\n",
      "    Det[GEN='f', NUM='pl'] -> 'ove'\n",
      "    Det[GEN='n', NUM='pl'] -> 'ova'\n",
      "    N[GEN='m', NUM='sg'] -> 'dječak'\n",
      "    N[GEN='m', NUM='pl'] -> 'dječaci'\n",
      "    N[GEN='f', NUM='sg'] -> 'djevojka'\n",
      "    N[GEN='f', NUM='pl'] -> 'djevojke'\n",
      "    V[NUM='sg'] -> 'trči'\n",
      "    V[NUM='sg'] -> 'pleše'\n",
      "    V[NUM='pl'] -> 'trče'\n",
      "    V[NUM='pl'] -> 'plešu'\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.load_parser('grammar.fcfg')\n",
    "print(cp.grammar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b05ba25e-7dd8-4b55-a8dd-001681086f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = 'ovaj dječak trči'\n",
    "sentence = 'ove djevojke plešu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e2cf290-eb6a-42ef-81b8-cb98c34b9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsiranje\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44a24dda-bd58-4d28-b0df-b1db635f7dd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svgling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\faks\\lib\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\faks\\lib\\site-packages\\nltk\\tree\\tree.py:783\u001b[0m, in \u001b[0;36mTree._repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_svg_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 783\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msvgling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_tree\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_tree(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_repr_svg_()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree(S[], [Tree(NP[NUM='pl'], [Tree(Det[GEN='f', NUM='pl'], ['ove']), Tree(N[GEN='f', NUM='pl'], ['djevojke'])]), Tree(VP[GEN=?m, NUM='pl'], [Tree(V[NUM='pl'], ['plešu'])])])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ucitaj parser i parsiraj recenicu\n",
    "\n",
    "trees = list(cp.parse(tokens))\n",
    "\n",
    "tree = trees[0]\n",
    "show_parse(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668e0c2-9091-429d-b141-fce925293746",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadatak 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2ea97-c5f0-4912-ac05-2eb00b643ca7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Napišite program za semantičko parsiranje sljedećih rečenica:\n",
    " ```\n",
    " Snoopy runs.\n",
    " Woodstock flies. \n",
    " ```\n",
    " * Napišite gramatiku obogaćenu značajkama koja pretvora tekst u odgovarajući $\\lambda$ izraz.\n",
    " * dajte model s evaluacijom koji će provjeriti istinistost sljedećih rečenica: `Snoopy runs, Woodstock flies,Woodstock runs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c751aed-8f76-4433-b99c-dfde2e6c313c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sem.fcfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile sem.fcfg\n",
    "% start S\n",
    "# Grammar Rules\n",
    "S[SEM=<?vp(?np)>] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "VP[SEM=?v] -> IV[SEM=?v]\n",
    "# Lexical Rules\n",
    "NP[SEM=<snoopy>] -> 'Snoopy'\n",
    "NP[SEM=<woodstock>] -> 'Woodstock'\n",
    "IV[SEM=<\\x.run(x)>] -> 'runs'\n",
    "IV[SEM=<\\x.fly(x)>] -> 'flies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fee570c-6044-4648-93fa-4ce54b1ffc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = 'Snoopy runs'\n",
    "sentence = 'Woodstock flies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53fe822a-2e59-47d8-ae4f-41fff6884f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly(woodstock)\n"
     ]
    }
   ],
   "source": [
    "# parsiranje\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "cp = nltk.load_parser('sem.fcfg')\n",
    "trees = cp.parse_all(tokens)\n",
    "\n",
    "tree = list(trees)\n",
    "\n",
    "\n",
    "for tree in trees:\n",
    "    print(tree.label()['SEM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "927089d7-c5ec-4a3b-810b-46fe8aacd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<run(snoopy)>]\n",
      "  (NP[SEM=<snoopy>] Snoopy)\n",
      "  (VP[SEM=<\\x.run(x)>] (IV[SEM=<\\x.run(x)>] runs)))\n",
      "run(snoopy)\n",
      "True\n",
      "(S[SEM=<fly(woodstock)>]\n",
      "  (NP[SEM=<woodstock>] Woodstock)\n",
      "  (VP[SEM=<\\x.fly(x)>] (IV[SEM=<\\x.fly(x)>] flies)))\n",
      "fly(woodstock)\n",
      "True\n",
      "(S[SEM=<run(woodstock)>]\n",
      "  (NP[SEM=<woodstock>] Woodstock)\n",
      "  (VP[SEM=<\\x.run(x)>] (IV[SEM=<\\x.run(x)>] runs)))\n",
      "run(woodstock)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# valuacija modela \n",
    "# postavljamo model\n",
    "v = \"\"\"\n",
    "    snoopy => s\n",
    "    woodstock => w\n",
    "    run => {s}\n",
    "    fly => {w}    \n",
    "    \n",
    "\"\"\"\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "\n",
    "g = nltk.Assignment(val.domain)\n",
    "m = nltk.Model(val.domain, val)\n",
    "sents = ['Snoopy runs','Woodstock flies','Woodstock runs']\n",
    "\n",
    "# nasa gramatika\n",
    "grammar_file = 'sem.fcfg'\n",
    "\n",
    "results = nltk.evaluate_sents(sents, grammar_file, m, g)\n",
    "# ispis semantičke reprezentacije i valuacije iste\n",
    "for result in results:\n",
    "    for (synrep, semrep, value) in result:\n",
    "        print(synrep)\n",
    "        print(semrep)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d306765-3b5c-444f-a4f9-d2e26270021d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadatak 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26008062-2ff9-4074-aa7d-3d65c4e5c19a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Implementirajte POS označavatelj koristeći naivni Bayes klasifikator koji će na temelju dane engleske riječi odrediti uPOS oznaku. Za značajke riječi odaberite prvih 100 najčešćih sufiksa duljine 1,2,3.  Možete iskoristiti Brownov korpus s u POS oznakama te treniranje i testiranje. Preciznost modela mora biti barem 70%. Utvrdite koja oznaka ima najveću $F_1$ ocjenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10475a1c-6a85-47b7-a172-300184e462ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 's', 'd', 'he', 't', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'and', 'g', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', 'an', 'm', 'i', 'ly', 'ion', 'en', 'al', 'be', 'nt', 'hat', 'st', 'his', 'th', 'le', 'll', 'by', 'ce', 'ts', 'me', 'se', 've', 'ut', 'was', 'for', 'ent', 'ch', 'w', 'k', 'ld', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', 'te', 'ty', 'ay', 'ot', 'p', 'nce', 'om', 'ter', 'ss', 'we', 'are', 'c', 'uld', 'ers', 'had', 'so', 'ey', 'one', 'all', 'not', 'ow', 'us', 'ons', 'ave', 'out', 'et', 'ar', 'ic', 'ge', 'de']\n"
     ]
    }
   ],
   "source": [
    "# korpus s POS oznakama\n",
    "from nltk.corpus import brown\n",
    "# POS odredjen sufiskom riječi?\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "\n",
    "# izracunaj frekvenciju sufiksa duljine 1,2,3\n",
    "words = [w.lower() for w in brown.words() if w.isalnum()]\n",
    "for word in words:\n",
    "    suffix_fdist[word[-1:]] += 1 # jednočlani sufiks\n",
    "    suffix_fdist[word[-2:]] += 1 # dvočlani sufiks\n",
    "    suffix_fdist[word[-3:]] += 1 # tročlani sufiks\n",
    "    \n",
    "# najcesci sufiks\n",
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "\n",
    "print(common_suffixes)\n",
    "\n",
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65c0ef87-c1f2-41b1-9b2a-028378c6c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'endswith(e)': True, 'endswith(s)': False, 'endswith(d)': False, 'endswith(he)': False, 'endswith(t)': False, 'endswith(n)': False, 'endswith(a)': False, 'endswith(of)': False, 'endswith(the)': False, 'endswith(y)': False, 'endswith(r)': False, 'endswith(to)': False, 'endswith(in)': False, 'endswith(f)': False, 'endswith(o)': False, 'endswith(ed)': False, 'endswith(nd)': False, 'endswith(is)': False, 'endswith(on)': False, 'endswith(l)': False, 'endswith(and)': False, 'endswith(g)': False, 'endswith(ng)': False, 'endswith(er)': False, 'endswith(as)': False, 'endswith(ing)': False, 'endswith(h)': False, 'endswith(at)': False, 'endswith(es)': False, 'endswith(or)': False, 'endswith(re)': False, 'endswith(it)': False, 'endswith(an)': False, 'endswith(m)': False, 'endswith(i)': False, 'endswith(ly)': False, 'endswith(ion)': False, 'endswith(en)': False, 'endswith(al)': False, 'endswith(be)': False, 'endswith(nt)': False, 'endswith(hat)': False, 'endswith(st)': False, 'endswith(his)': False, 'endswith(th)': False, 'endswith(le)': True, 'endswith(ll)': False, 'endswith(by)': False, 'endswith(ce)': False, 'endswith(ts)': False, 'endswith(me)': False, 'endswith(se)': False, 'endswith(ve)': False, 'endswith(ut)': False, 'endswith(was)': False, 'endswith(for)': False, 'endswith(ent)': False, 'endswith(ch)': False, 'endswith(w)': False, 'endswith(k)': False, 'endswith(ld)': False, 'endswith(rs)': False, 'endswith(ted)': False, 'endswith(ere)': False, 'endswith(her)': False, 'endswith(ne)': False, 'endswith(ns)': False, 'endswith(ith)': False, 'endswith(ad)': False, 'endswith(ry)': False, 'endswith(te)': False, 'endswith(ty)': False, 'endswith(ay)': False, 'endswith(ot)': False, 'endswith(p)': False, 'endswith(nce)': False, 'endswith(om)': False, 'endswith(ter)': False, 'endswith(ss)': False, 'endswith(we)': False, 'endswith(are)': False, 'endswith(c)': False, 'endswith(uld)': False, 'endswith(ers)': False, 'endswith(had)': False, 'endswith(so)': False, 'endswith(ey)': False, 'endswith(one)': False, 'endswith(all)': False, 'endswith(not)': False, 'endswith(ow)': False, 'endswith(us)': False, 'endswith(ons)': False, 'endswith(ave)': False, 'endswith(out)': False, 'endswith(et)': False, 'endswith(ar)': False, 'endswith(ic)': False, 'endswith(ge)': False, 'endswith(de)': False}\n"
     ]
    }
   ],
   "source": [
    "print(pos_features('ale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04504462-63f5-46f2-9a79-07362dac0824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DET'),\n",
       " ('in', 'ADP'),\n",
       " (\"''\", '.'),\n",
       " (\"Georgia's\", 'NOUN'),\n",
       " ('has', 'VERB')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skup podatka\n",
    "tagged_words = list(brown.tagged_words(categories='news',tagset='universal'))[:1000]\n",
    "random.shuffle(tagged_words)\n",
    "tagged_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07f0f57d-b53f-4999-bfdb-bfcf94e57214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(tagged_words) * 0.2)\n",
    "\n",
    "# popis rijeci za treniranje i testiranje\n",
    "train_tagged_words, test_tagged_words = tagged_words[size:], tagged_words[:size]\n",
    "\n",
    "# particioniraj na train i test\n",
    "train_set = [(pos_features(w), t) for (w,t) in train_tagged_words]\n",
    "test_set = [(pos_features(w), t) for (w,t) in test_tagged_words]\n",
    "\n",
    "\n",
    "\n",
    "# klasifikator\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# mjera preciznosti\n",
    "nltk.classify.accuracy(classifier, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9108120c-a1c7-49c7-9e41-b2f201b4c606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6a0361f-cc1b-4e84-8037-ce28d754f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            endswith(nd) = True             CONJ : NOUN   =     88.4 : 1.0\n",
      "            endswith(it) = True             PRON : NOUN   =     75.6 : 1.0\n",
      "             endswith(e) = True              DET : ADP    =     41.7 : 1.0\n",
      "             endswith(d) = True             CONJ : NOUN   =     29.5 : 1.0\n",
      "            endswith(to) = True              PRT : ADP    =     29.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9211f7a-8353-4f98-b9cb-a6f70e918d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = [t for (w,t) in test_tagged_words]\n",
    "test = [classifier.classify(pos_features(w)) for (w,t) in test_tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a94579e-8403-436d-ae68-7dd2b95f70a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tag | Prec.  | Recall | F-measure\n",
      "-----+--------+--------+-----------\n",
      "   . | 0.7059 | 1.0000 | 0.8276\n",
      " ADJ | 0.2500 | 0.3000 | 0.2727\n",
      " ADP | 0.7917 | 0.7600 | 0.7755\n",
      " ADV | 1.0000 | 0.2000 | 0.3333\n",
      "CONJ | 0.8571 | 0.8571 | 0.8571\n",
      " DET | 0.9583 | 0.7419 | 0.8364\n",
      "NOUN | 0.7419 | 0.7302 | 0.7360\n",
      " NUM | 0.5000 | 1.0000 | 0.6667\n",
      "PRON | 1.0000 | 0.6667 | 0.8000\n",
      " PRT | 0.4000 | 1.0000 | 0.5714\n",
      "VERB | 0.8148 | 0.7586 | 0.7857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "cm = ConfusionMatrix(reference, test)\n",
    "print(cm.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e6888-7b9e-45f2-942c-313c9d3ba733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
